{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load dataset\n",
    "\n",
    "# from datasets import load_dataset\n",
    "# from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "# tokenizer = ByteLevelBPETokenizer()\n",
    "# dataset = load_dataset(\"roneneldan/TinyStories\")\n",
    "\n",
    "# # Specify the split you want to save (e.g., \"train\", \"validation\", \"test\")\n",
    "# split = \"train\"\n",
    "\n",
    "# # Get the desired split from the dataset\n",
    "# subset = dataset[split]\n",
    "\n",
    "# # Save the subset to a text file\n",
    "# subset.to_csv(\"tinystories-train.txt\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- imports --------\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import wandb\n",
    "import os\n",
    "import tokenizers\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "assert device == 'cuda', \"This notebook is not optimized for CPU\"\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"sae_learning_rate\": 5e-5,\n",
    "    \"model_embedding_layer\": 6,\n",
    "    \"eval_interval\": 500,\n",
    "    \"max_iters\": 60000, \n",
    "    \"H\": 32, # hidden dimension size\n",
    "    \"B\": 64,\n",
    "    \"T\": 256,\n",
    "    \"C\": 256,\n",
    "    \"feedforward_factor\": 3,\n",
    "    \"n_heads\": 8,\n",
    "    \"n_layers\": 12,\n",
    "    \"tokenizer_vocab_size\": 2**13,\n",
    "    \"git_hash\": os.popen(\"git rev-parse HEAD\").read().strip()\n",
    "}\n",
    "\n",
    "# initial\n",
    "for k,v in config.items():\n",
    "    locals ()[k] = v\n",
    "\n",
    "\n",
    "#wandb.init(\n",
    "#    project = \"tinystories\",\n",
    "#    config = config,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# stories_data = []\n",
    "# data_dir = './data'\n",
    "# for filename in os.listdir(data_dir):\n",
    "#     file_path = os.path.join(data_dir, filename)\n",
    "#     if filename.endswith('.json'):\n",
    "#         with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#             data = json.load(f)\n",
    "#             stories_data.extend(data)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the tinystories tokenizer\n",
    "# tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "#     \"./tiny-stories-bpe-vocab.json\", \n",
    "#     \"./tiny-stories-bpe-merges.txt\"\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# def encode(text):\n",
    "#     return torch.tensor(tokenizer.encode(text).ids, dtype=torch.int64)\n",
    "# def decode(encoded_text):\n",
    "#     return tokenizer.decode(encoded_text.tolist())\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# encoded_stories = [encode(story['story']) for story in tqdm(stories_data, desc=\"Encoding stories\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the encoded stories to a file\n",
    "# torch.save(encoded_stories, 'encoded-stories.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('tinystories-train.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1916206969\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479051742.25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1916206969/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in lines:  20550005\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in lines: \", len(text.split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "\"One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
      "\n",
      "Lily went to her mom and said, \"\"Mom, I found this needle. Can you share it with me and sew my shirt?\"\" Her mom smiled and said, \"\"Yes, Lily, we can share the needle and fix your shirt.\"\"\n",
      "\n",
      "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\"\n",
      "\"Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\n",
      "\n",
      "One day, Beep was driving in the park when he saw a big tree. The tree had many leaves that wer\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = ['tinystories-train.txt']\n",
    "# tokenizer = tokenizers.ByteLevelBPETokenizer()\n",
    "\n",
    "# tokenizer.train(files=paths, vocab_size=tokenizer_vocab_size, min_frequency=2)\n",
    "\n",
    "# tokenizer.save_model('.', 'tiny-stories-bpe')\n",
    "\n",
    "\n",
    "\n",
    "# enc = tokenizer.encode(\"She sells sea shells by the sea shore!\")\n",
    "# tokenizer.decode(enc.ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "    \"./tiny-stories-bpe-vocab.json\", \n",
    "    \"./tiny-stories-bpe-merges.txt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6132]\n",
      "hello\n",
      "vocab size:  8192\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def encode(text):\n",
    "    return tokenizer.encode(text).ids\n",
    "def decode(encoded_text):\n",
    "    return tokenizer.decode(encoded_text)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def batch_encode(text, batch_size):\n",
    "    tokens = []\n",
    "    for i in tqdm(range(0, len(text), batch_size)):\n",
    "        tokens.extend(encode(text[i:i+batch_size]))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "hello_encoded = encode(\"hello\")\n",
    "print(hello_encoded)\n",
    "print(decode(hello_encoded))\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "print(\"vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 52.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory used by sample_encoded:  1.2918853759765625 MB\n"
     ]
    }
   ],
   "source": [
    "sample_text = text[:200000]\n",
    "sample_encoded = batch_encode(sample_text, 20000)\n",
    "\n",
    "# get the amount of memory used by sample_encoded\n",
    "def recursive_memory_usage(python_obj):\n",
    "    if isinstance(python_obj, (str, int, float)):\n",
    "        return python_obj.__sizeof__()\n",
    "    if isinstance(python_obj, dict):\n",
    "        return sum([recursive_memory_usage(v) for v in python_obj.values()])\n",
    "    if isinstance(python_obj, list):\n",
    "        return sum([recursive_memory_usage(v) for v in python_obj])\n",
    "    return python_obj.__sizeof__()\n",
    "\n",
    "print(\"memory used by sample_encoded: \", recursive_memory_usage(sample_encoded) / 1024**2, \"MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  10000\n",
      "length of dataset in tokens:  2457\n",
      "characters per token:  4.07000407000407\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text[:10000]))\n",
    "print(\"length of dataset in tokens: \", len(encode(text[:10000])))\n",
    "chars_per_token = len(text[:10000]) / len(encode(text[:10000]))\n",
    "print(\"characters per token: \", chars_per_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_text = batch_encode(text, 200000)\n",
    "# # data = torch.tensor(encode(text), dtype=torch.int64)\n",
    "# data = torch.tensor(encoded_text, dtype=torch.int64, device='cuda')\n",
    "# print(data.dtype)\n",
    "# print(data.size())\n",
    "# print(data.device)\n",
    "# torch.save(data, 'tiny-stories-train.pt')\n",
    "# encoded_text = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from tiny-stories-train.pt\n",
    "data = torch.load('tiny-stories-train.pt', map_location='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468832276"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([421949048])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  83, 3206,  198,    1,  421,  356,   11,  258,  397,  447,  501,  364,\n",
       "         596,  258, 3736,  316,  309,  759,   13,  313,  704,  304,  282, 2966,\n",
       "         265,  359,  342,  304,  788,  304,  282, 2120,   13,  364,  445,  265,\n",
       "         949,  262, 3736,  342,  309,  365,   11,  350,  338,  461, 5198,  258,\n",
       "        2228,  345,  309, 2500,   13,  198,  198,  343,  469,  265,  309,  365,\n",
       "         264,  327,   11,  329,  771,   11,  335,  596,  741, 3736,   13, 1282,\n",
       "         346,  949,  304,  342,  519,  264, 5198,  652, 2500,  478,  866,  365,\n",
       "         499,  264,  327,   11,  329,  832,   11,  364,   11,  363,  472,  949,\n",
       "         262, 3736,  264, 1306,  627, 2500,  416,  198,  198, 4625,   11,  362,\n",
       "        1656,  262, 3736,  264, 7930,  262, 2228,  345,  364,  371, 2500,   13,\n",
       "         410,  282,  385, 2966,  366,  449,  788,  362,  430, 2502,  264, 1762,\n",
       "         757,  573,   13, 1453,  362, 1444,   11,  364,  858,  309,  365,  366,\n",
       "        2502,  262, 3736,  264, 5150,  309, 2500,   13,  320,  897,  514,  405,\n",
       "         788,  362,  360, 1656,  264, 1370,  567,  408,  198,    1,  432,  448,\n",
       "         258,  396,   11,  400,  282,  258,  397,  565,  501, 2632,  592,   13,\n",
       "        2632,  592,  504,  265,  437,  848,  264,  359,  316,  262,  734,   13,\n",
       "        2632,  592,  282,  258, 2188,  565,  788,  278,  667,  360,  590, 4830,\n",
       "          13, 5204, 4830,  564, 2632,  592,  405,  264, 1123,   13,  198,  198,\n",
       "         421,  356,   11, 2632,  592,  282, 3476,  316,  262,  570,  589,  278,\n",
       "         414,  258,  407,  680,   13,  299,  680,  360,  791, 1508,  357,  430,\n",
       "        4175,   13, 2632,  592,  616,  713,  262, 1508, 1544,  264,  445,  265,\n",
       "         359,  342,  449,   13, 2632], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:T+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text\\n\"One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"\"Mom, I found this needle. Can you share it with me and sew my shirt?\"\" Her mom smiled and said, \"\"Yes, Lily, we can share the needle and fix your shirt.\"\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\"\\n\"Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\\n\\nOne day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were falling. Beep liked how the leaves fall and wanted to play with them. Be'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(train_data[:T+1].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:T]\n",
    "y = train_data[1:T+1]\n",
    "for t in range(T):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    # print(\"when we see the text\", context, \"we predict the next character is\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1337)\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(0, data.size(0) - T, (B,)) # 4 random locations we can sample from\n",
    "    x = torch.stack([data[i:i+T] for i in ix]) # random sequences\n",
    "    y = torch.stack([data[i+1:i+T+1] for i in ix]) # next character for each random sequence\n",
    "\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "\n",
    "for b in range(B):\n",
    "    for t in range(T): # for each of the characters in the sample\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "# torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    '''One Head of self-attention'''\n",
    "    def __init__(self, H):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(C, H, bias=False)\n",
    "        self.key = nn.Linear(C, H, bias=False)\n",
    "        self.value = nn.Linear(C, H, bias=False)\n",
    "        # self.output = nn.Linear(H, C, bias=False) # output matrix\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(T, T)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Query and Key matrices for the attention mechanism\n",
    "        # x: 8 tokens\n",
    "        # Q: 16 tall (arbitrary), 32 long channels\n",
    "        # K: 16 tall (arbitrary), 32 long channels\n",
    "\n",
    "        query_vectors = self.query(x)\n",
    "        key_vectors = self.key(x)\n",
    "\n",
    "\n",
    "        # Attention masking(so we can't look into the past):\n",
    "\n",
    "        tril = self.tril\n",
    "        wei = torch.zeros(T, T) \n",
    "        wei = wei.masked_fill(tril == 0, float('-inf')) # set the upper triangular to -inf\n",
    "        # xbow = wei @ x # apply the mask to the input, bag of words because simple avg.\n",
    "\n",
    "        # multiply the two to get the attention weights\n",
    "        attention_pattern = query_vectors @ key_vectors.transpose(-2, -1) # T, T\n",
    "        attention_pattern = attention_pattern / (H ** 0.5) # scale the attention pattern for numerical stability\n",
    "        attention_weights = F.softmax(attention_pattern + wei, dim=-1) # T, T (the row dimension is the query)\n",
    "\n",
    "        value_vectors = self.value(x) # the direction we should go in the embedding space for each token (ie more blue) T, H\n",
    "\n",
    "        # apply the attention weights to the value vectors\n",
    "        context = attention_weights @ value_vectors # T, H\n",
    "\n",
    "        # project back into original space from value space\n",
    "        # return self.output(context)\n",
    "        return context\n",
    "\n",
    "x = torch.randn(B,T,C)\n",
    "head = Head(H)\n",
    "# head(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    '''Multiple heads of self-attention'''\n",
    "    def __init__(self, H, C, n_heads): # H is head embedding space size, n_heads is number of heads\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(H) for _ in range(n_heads)])\n",
    "        self.combine_heads = nn.Linear(H*n_heads, C)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        x = self.combine_heads(x)  # T, C\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = MultiHeadAttention(H, C, n_heads)\n",
    "head.heads[0].forward(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    '''Feed-forward neural network'''\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(C, C * feedforward_factor),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(C * feedforward_factor, C),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    '''Layer normalization'''\n",
    "    def __init__(self, C, use_affine=True):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(C)) if use_affine else None\n",
    "        self.beta = nn.Parameter(torch.zeros(C)) if use_affine else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        if self.gamma is not None and self.beta is not None:\n",
    "            return self.gamma * (x - mean) / (std + 1e-6) + self.beta\n",
    "        else:\n",
    "            return (x - mean) / (std + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    '''Transformer block'''\n",
    "    def __init__(self, H, C, n_heads):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(H, C, n_heads)\n",
    "        self.ff = FeedForward(C)\n",
    "        self.norm1 = LayerNorm(C, use_affine=True)\n",
    "        self.norm2 = LayerNorm(C, use_affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attention(self.norm1(x))\n",
    "        x = x + self.ff(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.6126,  0.3946, -1.4367,  ..., -1.6661,  0.1460,  0.4504],\n",
       "          [ 2.1239, -2.4500, -1.5640,  ..., -0.6205,  0.2284, -0.6869],\n",
       "          [ 2.2312, -1.2311, -1.4093,  ..., -1.2511, -0.0832, -0.8157],\n",
       "          ...,\n",
       "          [ 1.6009, -0.6114, -0.1871,  ..., -0.8554,  0.4884, -1.0227],\n",
       "          [ 2.4410, -1.3228, -0.7426,  ..., -1.3044,  0.3075,  0.1473],\n",
       "          [ 1.5568, -0.9135,  0.8263,  ..., -0.6930, -0.6212, -0.6414]]],\n",
       "        device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " None,\n",
       " tensor(0., device='cuda:0'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layers):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, C) \n",
    "        self.position_embedding_table = nn.Embedding(T, C)\n",
    "        self.lm_head = nn.Linear(C, vocab_size)\n",
    "        self.layers = nn.ModuleList([Block(H, C, n_heads) for _ in range(n_layers)])\n",
    "    \n",
    "    def forward(self, idx, targets=None, return_residuals=None):\n",
    "        B, T = idx.shape\n",
    "        token_emb = self.token_embedding_table(idx) # batch_dim, sequence_dim, embedding_dim\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T))\n",
    "        x = token_emb + pos_emb # token identities and positions contained\n",
    "\n",
    "        if return_residuals == \"first_embedding\":\n",
    "            return x\n",
    "\n",
    "        # def excess_kurtosis(emb):\n",
    "        #     mean = torch.mean(emb, dim=-1, keepdim=True) # BxTx1\n",
    "        #     std = torch.std(emb, dim=-1, keepdim=True) # BxTx1\n",
    "\n",
    "        #     centralized = emb - mean #BxTxC\n",
    "        #     fourth_moment = torch.mean(centralized**4, dim=-1, keepdim=True) # BxTx1\n",
    "        #     kurtosis = torch.squeeze(fourth_moment / std**4, dim=-1) # BxT\n",
    "        #     # view as a 1d vector\n",
    "        #     kurtosis = kurtosis.view(-1) - 3\n",
    "        #     # make each one min 0\n",
    "        #     kurtosis = torch.maximum(kurtosis, torch.tensor(0.0))\n",
    "        #     # sum over the vector\n",
    "        #     kurtosis = torch.sum(kurtosis)\n",
    "        #     return kurtosis\n",
    "\n",
    "\n",
    "        # kurtosis_sum = torch.tensor(0.0)\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            # kurtosis_sum += excess_kurtosis(x)\n",
    "            if return_residuals is not None and i == return_residuals:\n",
    "                return x\n",
    "        \n",
    "        # kurtosis_avg = kurtosis_sum / (len(self.layers) * T * B)\n",
    "        kurtosis_avg = torch.tensor(0.0)\n",
    "\n",
    "        logits = self.lm_head(x) # batch_dim, sequence_dim, vocab_size\n",
    "\n",
    "        batch_dim, sequence_dim, embedding_dim = logits.size()\n",
    "\n",
    "        # loss = F.cross_entropy(logits, targets) this won't work because we need 1d logits and 1d targets\n",
    "        # one-hot-vectors are a line in the x-dimension, so the shape of shape of the logits should be (-1, vocab_size).\n",
    "\n",
    "        if targets is None:\n",
    "            return logits, None, kurtosis_avg\n",
    "        else:\n",
    "            # a list of all the predictions, reguardles of batch.\n",
    "            # xdim: probabilities of each character in the vocab (embedding_dim=vocab_size)\n",
    "            # ydim: all predictions for all batches flattened (batch_dim*sequence_dim)\n",
    "            logits_loss_view = logits.view(-1, vocab_size) \n",
    "            # targets loss view\n",
    "            # xdim: all targets for all batches flattened (batch_dim*sequence_dim)\n",
    "            # so this would be like, [1,4,5,1,2,3, ...]\n",
    "            # where each number is the correct next index of the one hot vector\n",
    "            targets_loss_view = targets.view(-1)\n",
    "            loss = F.cross_entropy(logits_loss_view, targets_loss_view)\n",
    "            return logits, loss, kurtosis_avg\n",
    "\n",
    "    def generate(self, idx, max_new_tokens, temperature=0.5):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx[:,-T:])\n",
    "            # get the predictions of the last token\n",
    "            last_token_logits = logits[:, -1, :] # all batches, last token, all probabilities\n",
    "            # apply temperature\n",
    "            last_token_logits = last_token_logits / temperature\n",
    "            # softmax to get probabilities\n",
    "            probabilities = F.softmax(last_token_logits, dim=-1)\n",
    "            # sample from the probabilities\n",
    "            next_token = torch.multinomial(probabilities, num_samples=1)\n",
    "            # add the new token to the idx tensor\n",
    "            idx = torch.cat((idx, next_token), dim=1)\n",
    "        return idx\n",
    "    def prompt_model(self, prompt, max_new_tokens, temperature=0.5):\n",
    "        autoregressive_seq = encode(prompt)\n",
    "        for _ in range(max_new_tokens):\n",
    "            prediction_index = len(autoregressive_seq)-1\n",
    "\n",
    "            model_input = torch.tensor(autoregressive_seq)\n",
    "            \n",
    "            while model_input.shape[0] < T:\n",
    "                pad_token = torch.tensor(encode(\"\\n\"))\n",
    "                model_input = torch.cat((model_input, pad_token), dim=0)\n",
    "\n",
    "            model_input\n",
    "            model_input = model_input.unsqueeze(0)\n",
    "\n",
    "            logits, loss, kurtosis_avg = model(model_input)\n",
    "            prediction_token = logits[:, prediction_index, :] / temperature\n",
    "            probabilities = F.softmax(prediction_token, dim=-1)\n",
    "            next_token = torch.multinomial(probabilities, num_samples=1)\n",
    "            next_token = next_token.item()\n",
    "\n",
    "            autoregressive_seq.append(next_token)\n",
    "        # get the autoregressive sequence\n",
    "        return decode(autoregressive_seq)\n",
    "    def get_embedding(self, prompt, override_model_embedding_layer=None):\n",
    "        if override_model_embedding_layer is None:\n",
    "            selected_model_embedding_layer = model_embedding_layer\n",
    "        else:\n",
    "            selected_model_embedding_layer = override_model_embedding_layer\n",
    "        sequence = encode(prompt)\n",
    "        model_input = torch.tensor(sequence)\n",
    "        sequence_index = len(sequence) - 1\n",
    "        while model_input.shape[0] < T:\n",
    "            pad_token = torch.tensor(encode(\"\\n\"))\n",
    "            model_input = torch.cat((model_input, pad_token), dim=0)\n",
    "        model_input = model_input.unsqueeze(0)\n",
    "        embedding = self.forward(model_input, return_residuals=selected_model_embedding_layer)\n",
    "        # remove the batch dimension\n",
    "        embedding = embedding.squeeze(0)[sequence_index]\n",
    "        return embedding\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "model = GPT(n_layers)\n",
    "# logits, loss, kurtosis_avg = model(xb, yb)\n",
    "# print(logits.shape)\n",
    "# print(loss)\n",
    "# print(kurtosis_avg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_idx = torch.zeros(1, T).long()\n",
    "model.forward(idx=test_idx)\n",
    "# decode(model.generate(idx=test_idx, max_new_tokens=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (token_embedding_table): Embedding(8192, 256)\n",
       "  (position_embedding_table): Embedding(256, 256)\n",
       "  (lm_head): Linear(in_features=256, out_features=8192, bias=True)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x Block(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x Head(\n",
       "            (query): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (key): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=32, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (combine_heads): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=768, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in the model:  12160000\n"
     ]
    }
   ],
   "source": [
    "# get the number of parameters in the model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"number of parameters in the model: \", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([468832276])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits, loss = self(idx[:,-T:])\n",
    "\n",
    "idx = torch.zeros(1, 1).long()\n",
    "idx[:,-T:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.token_embedding_table.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iters = 10\n",
    "eval_interval = 300\n",
    "@torch.no_grad()\n",
    "def estimate_loss(is_last=False):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        real_iters = eval_iters\n",
    "        if is_last and split == 'val':  # increase last eval to mitigate noise\n",
    "            real_iters *= 10 \n",
    "        losses = torch.zeros(real_iters)\n",
    "        for k in range(real_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss, kurtosis_avg = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean() / chars_per_token\n",
    "    model.train()\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter_to_data_ratio=0.028818645420903996\n",
      "token_embedding_table.weight: 2097152\n",
      "lm_head.weight: 2097152\n",
      "layers.0.ff.net.0.weight: 196608\n",
      "layers.0.ff.net.2.weight: 196608\n",
      "layers.1.ff.net.0.weight: 196608\n",
      "layers.1.ff.net.2.weight: 196608\n",
      "layers.2.ff.net.0.weight: 196608\n",
      "layers.2.ff.net.2.weight: 196608\n",
      "layers.3.ff.net.0.weight: 196608\n",
      "layers.3.ff.net.2.weight: 196608\n",
      "layers.4.ff.net.0.weight: 196608\n",
      "layers.4.ff.net.2.weight: 196608\n",
      "layers.5.ff.net.0.weight: 196608\n",
      "layers.5.ff.net.2.weight: 196608\n",
      "layers.6.ff.net.0.weight: 196608\n",
      "layers.6.ff.net.2.weight: 196608\n",
      "layers.7.ff.net.0.weight: 196608\n",
      "layers.7.ff.net.2.weight: 196608\n",
      "layers.8.ff.net.0.weight: 196608\n",
      "layers.8.ff.net.2.weight: 196608\n",
      "layers.9.ff.net.0.weight: 196608\n",
      "layers.9.ff.net.2.weight: 196608\n",
      "layers.10.ff.net.0.weight: 196608\n",
      "layers.10.ff.net.2.weight: 196608\n",
      "layers.11.ff.net.0.weight: 196608\n",
      "layers.11.ff.net.2.weight: 196608\n",
      "position_embedding_table.weight: 65536\n",
      "layers.0.attention.combine_heads.weight: 65536\n",
      "layers.1.attention.combine_heads.weight: 65536\n",
      "layers.2.attention.combine_heads.weight: 65536\n",
      "layers.3.attention.combine_heads.weight: 65536\n",
      "layers.4.attention.combine_heads.weight: 65536\n",
      "layers.5.attention.combine_heads.weight: 65536\n",
      "layers.6.attention.combine_heads.weight: 65536\n",
      "layers.7.attention.combine_heads.weight: 65536\n",
      "layers.8.attention.combine_heads.weight: 65536\n",
      "layers.9.attention.combine_heads.weight: 65536\n",
      "layers.10.attention.combine_heads.weight: 65536\n",
      "layers.11.attention.combine_heads.weight: 65536\n",
      "lm_head.bias: 8192\n",
      "layers.0.attention.heads.0.query.weight: 8192\n",
      "layers.0.attention.heads.0.key.weight: 8192\n",
      "layers.0.attention.heads.0.value.weight: 8192\n",
      "layers.0.attention.heads.1.query.weight: 8192\n",
      "layers.0.attention.heads.1.key.weight: 8192\n",
      "layers.0.attention.heads.1.value.weight: 8192\n",
      "layers.0.attention.heads.2.query.weight: 8192\n",
      "layers.0.attention.heads.2.key.weight: 8192\n",
      "layers.0.attention.heads.2.value.weight: 8192\n",
      "layers.0.attention.heads.3.query.weight: 8192\n",
      "layers.0.attention.heads.3.key.weight: 8192\n",
      "layers.0.attention.heads.3.value.weight: 8192\n",
      "layers.0.attention.heads.4.query.weight: 8192\n",
      "layers.0.attention.heads.4.key.weight: 8192\n",
      "layers.0.attention.heads.4.value.weight: 8192\n",
      "layers.0.attention.heads.5.query.weight: 8192\n",
      "layers.0.attention.heads.5.key.weight: 8192\n",
      "layers.0.attention.heads.5.value.weight: 8192\n",
      "layers.0.attention.heads.6.query.weight: 8192\n",
      "layers.0.attention.heads.6.key.weight: 8192\n",
      "layers.0.attention.heads.6.value.weight: 8192\n",
      "layers.0.attention.heads.7.query.weight: 8192\n",
      "layers.0.attention.heads.7.key.weight: 8192\n",
      "layers.0.attention.heads.7.value.weight: 8192\n",
      "layers.1.attention.heads.0.query.weight: 8192\n",
      "layers.1.attention.heads.0.key.weight: 8192\n",
      "layers.1.attention.heads.0.value.weight: 8192\n",
      "layers.1.attention.heads.1.query.weight: 8192\n",
      "layers.1.attention.heads.1.key.weight: 8192\n",
      "layers.1.attention.heads.1.value.weight: 8192\n",
      "layers.1.attention.heads.2.query.weight: 8192\n",
      "layers.1.attention.heads.2.key.weight: 8192\n",
      "layers.1.attention.heads.2.value.weight: 8192\n",
      "layers.1.attention.heads.3.query.weight: 8192\n",
      "layers.1.attention.heads.3.key.weight: 8192\n",
      "layers.1.attention.heads.3.value.weight: 8192\n",
      "layers.1.attention.heads.4.query.weight: 8192\n",
      "layers.1.attention.heads.4.key.weight: 8192\n",
      "layers.1.attention.heads.4.value.weight: 8192\n",
      "layers.1.attention.heads.5.query.weight: 8192\n",
      "layers.1.attention.heads.5.key.weight: 8192\n",
      "layers.1.attention.heads.5.value.weight: 8192\n",
      "layers.1.attention.heads.6.query.weight: 8192\n",
      "layers.1.attention.heads.6.key.weight: 8192\n",
      "layers.1.attention.heads.6.value.weight: 8192\n",
      "layers.1.attention.heads.7.query.weight: 8192\n",
      "layers.1.attention.heads.7.key.weight: 8192\n",
      "layers.1.attention.heads.7.value.weight: 8192\n",
      "layers.2.attention.heads.0.query.weight: 8192\n",
      "layers.2.attention.heads.0.key.weight: 8192\n",
      "layers.2.attention.heads.0.value.weight: 8192\n",
      "layers.2.attention.heads.1.query.weight: 8192\n",
      "layers.2.attention.heads.1.key.weight: 8192\n",
      "layers.2.attention.heads.1.value.weight: 8192\n",
      "layers.2.attention.heads.2.query.weight: 8192\n",
      "layers.2.attention.heads.2.key.weight: 8192\n",
      "layers.2.attention.heads.2.value.weight: 8192\n",
      "layers.2.attention.heads.3.query.weight: 8192\n",
      "layers.2.attention.heads.3.key.weight: 8192\n",
      "layers.2.attention.heads.3.value.weight: 8192\n",
      "layers.2.attention.heads.4.query.weight: 8192\n",
      "layers.2.attention.heads.4.key.weight: 8192\n",
      "layers.2.attention.heads.4.value.weight: 8192\n",
      "layers.2.attention.heads.5.query.weight: 8192\n",
      "layers.2.attention.heads.5.key.weight: 8192\n",
      "layers.2.attention.heads.5.value.weight: 8192\n",
      "layers.2.attention.heads.6.query.weight: 8192\n",
      "layers.2.attention.heads.6.key.weight: 8192\n",
      "layers.2.attention.heads.6.value.weight: 8192\n",
      "layers.2.attention.heads.7.query.weight: 8192\n",
      "layers.2.attention.heads.7.key.weight: 8192\n",
      "layers.2.attention.heads.7.value.weight: 8192\n",
      "layers.3.attention.heads.0.query.weight: 8192\n",
      "layers.3.attention.heads.0.key.weight: 8192\n",
      "layers.3.attention.heads.0.value.weight: 8192\n",
      "layers.3.attention.heads.1.query.weight: 8192\n",
      "layers.3.attention.heads.1.key.weight: 8192\n",
      "layers.3.attention.heads.1.value.weight: 8192\n",
      "layers.3.attention.heads.2.query.weight: 8192\n",
      "layers.3.attention.heads.2.key.weight: 8192\n",
      "layers.3.attention.heads.2.value.weight: 8192\n",
      "layers.3.attention.heads.3.query.weight: 8192\n",
      "layers.3.attention.heads.3.key.weight: 8192\n",
      "layers.3.attention.heads.3.value.weight: 8192\n",
      "layers.3.attention.heads.4.query.weight: 8192\n",
      "layers.3.attention.heads.4.key.weight: 8192\n",
      "layers.3.attention.heads.4.value.weight: 8192\n",
      "layers.3.attention.heads.5.query.weight: 8192\n",
      "layers.3.attention.heads.5.key.weight: 8192\n",
      "layers.3.attention.heads.5.value.weight: 8192\n",
      "layers.3.attention.heads.6.query.weight: 8192\n",
      "layers.3.attention.heads.6.key.weight: 8192\n",
      "layers.3.attention.heads.6.value.weight: 8192\n",
      "layers.3.attention.heads.7.query.weight: 8192\n",
      "layers.3.attention.heads.7.key.weight: 8192\n",
      "layers.3.attention.heads.7.value.weight: 8192\n",
      "layers.4.attention.heads.0.query.weight: 8192\n",
      "layers.4.attention.heads.0.key.weight: 8192\n",
      "layers.4.attention.heads.0.value.weight: 8192\n",
      "layers.4.attention.heads.1.query.weight: 8192\n",
      "layers.4.attention.heads.1.key.weight: 8192\n",
      "layers.4.attention.heads.1.value.weight: 8192\n",
      "layers.4.attention.heads.2.query.weight: 8192\n",
      "layers.4.attention.heads.2.key.weight: 8192\n",
      "layers.4.attention.heads.2.value.weight: 8192\n",
      "layers.4.attention.heads.3.query.weight: 8192\n",
      "layers.4.attention.heads.3.key.weight: 8192\n",
      "layers.4.attention.heads.3.value.weight: 8192\n",
      "layers.4.attention.heads.4.query.weight: 8192\n",
      "layers.4.attention.heads.4.key.weight: 8192\n",
      "layers.4.attention.heads.4.value.weight: 8192\n",
      "layers.4.attention.heads.5.query.weight: 8192\n",
      "layers.4.attention.heads.5.key.weight: 8192\n",
      "layers.4.attention.heads.5.value.weight: 8192\n",
      "layers.4.attention.heads.6.query.weight: 8192\n",
      "layers.4.attention.heads.6.key.weight: 8192\n",
      "layers.4.attention.heads.6.value.weight: 8192\n",
      "layers.4.attention.heads.7.query.weight: 8192\n",
      "layers.4.attention.heads.7.key.weight: 8192\n",
      "layers.4.attention.heads.7.value.weight: 8192\n",
      "layers.5.attention.heads.0.query.weight: 8192\n",
      "layers.5.attention.heads.0.key.weight: 8192\n",
      "layers.5.attention.heads.0.value.weight: 8192\n",
      "layers.5.attention.heads.1.query.weight: 8192\n",
      "layers.5.attention.heads.1.key.weight: 8192\n",
      "layers.5.attention.heads.1.value.weight: 8192\n",
      "layers.5.attention.heads.2.query.weight: 8192\n",
      "layers.5.attention.heads.2.key.weight: 8192\n",
      "layers.5.attention.heads.2.value.weight: 8192\n",
      "layers.5.attention.heads.3.query.weight: 8192\n",
      "layers.5.attention.heads.3.key.weight: 8192\n",
      "layers.5.attention.heads.3.value.weight: 8192\n",
      "layers.5.attention.heads.4.query.weight: 8192\n",
      "layers.5.attention.heads.4.key.weight: 8192\n",
      "layers.5.attention.heads.4.value.weight: 8192\n",
      "layers.5.attention.heads.5.query.weight: 8192\n",
      "layers.5.attention.heads.5.key.weight: 8192\n",
      "layers.5.attention.heads.5.value.weight: 8192\n",
      "layers.5.attention.heads.6.query.weight: 8192\n",
      "layers.5.attention.heads.6.key.weight: 8192\n",
      "layers.5.attention.heads.6.value.weight: 8192\n",
      "layers.5.attention.heads.7.query.weight: 8192\n",
      "layers.5.attention.heads.7.key.weight: 8192\n",
      "layers.5.attention.heads.7.value.weight: 8192\n",
      "layers.6.attention.heads.0.query.weight: 8192\n",
      "layers.6.attention.heads.0.key.weight: 8192\n",
      "layers.6.attention.heads.0.value.weight: 8192\n",
      "layers.6.attention.heads.1.query.weight: 8192\n",
      "layers.6.attention.heads.1.key.weight: 8192\n",
      "layers.6.attention.heads.1.value.weight: 8192\n",
      "layers.6.attention.heads.2.query.weight: 8192\n",
      "layers.6.attention.heads.2.key.weight: 8192\n",
      "layers.6.attention.heads.2.value.weight: 8192\n",
      "layers.6.attention.heads.3.query.weight: 8192\n",
      "layers.6.attention.heads.3.key.weight: 8192\n",
      "layers.6.attention.heads.3.value.weight: 8192\n",
      "layers.6.attention.heads.4.query.weight: 8192\n",
      "layers.6.attention.heads.4.key.weight: 8192\n",
      "layers.6.attention.heads.4.value.weight: 8192\n",
      "layers.6.attention.heads.5.query.weight: 8192\n",
      "layers.6.attention.heads.5.key.weight: 8192\n",
      "layers.6.attention.heads.5.value.weight: 8192\n",
      "layers.6.attention.heads.6.query.weight: 8192\n",
      "layers.6.attention.heads.6.key.weight: 8192\n",
      "layers.6.attention.heads.6.value.weight: 8192\n",
      "layers.6.attention.heads.7.query.weight: 8192\n",
      "layers.6.attention.heads.7.key.weight: 8192\n",
      "layers.6.attention.heads.7.value.weight: 8192\n",
      "layers.7.attention.heads.0.query.weight: 8192\n",
      "layers.7.attention.heads.0.key.weight: 8192\n",
      "layers.7.attention.heads.0.value.weight: 8192\n",
      "layers.7.attention.heads.1.query.weight: 8192\n",
      "layers.7.attention.heads.1.key.weight: 8192\n",
      "layers.7.attention.heads.1.value.weight: 8192\n",
      "layers.7.attention.heads.2.query.weight: 8192\n",
      "layers.7.attention.heads.2.key.weight: 8192\n",
      "layers.7.attention.heads.2.value.weight: 8192\n",
      "layers.7.attention.heads.3.query.weight: 8192\n",
      "layers.7.attention.heads.3.key.weight: 8192\n",
      "layers.7.attention.heads.3.value.weight: 8192\n",
      "layers.7.attention.heads.4.query.weight: 8192\n",
      "layers.7.attention.heads.4.key.weight: 8192\n",
      "layers.7.attention.heads.4.value.weight: 8192\n",
      "layers.7.attention.heads.5.query.weight: 8192\n",
      "layers.7.attention.heads.5.key.weight: 8192\n",
      "layers.7.attention.heads.5.value.weight: 8192\n",
      "layers.7.attention.heads.6.query.weight: 8192\n",
      "layers.7.attention.heads.6.key.weight: 8192\n",
      "layers.7.attention.heads.6.value.weight: 8192\n",
      "layers.7.attention.heads.7.query.weight: 8192\n",
      "layers.7.attention.heads.7.key.weight: 8192\n",
      "layers.7.attention.heads.7.value.weight: 8192\n",
      "layers.8.attention.heads.0.query.weight: 8192\n",
      "layers.8.attention.heads.0.key.weight: 8192\n",
      "layers.8.attention.heads.0.value.weight: 8192\n",
      "layers.8.attention.heads.1.query.weight: 8192\n",
      "layers.8.attention.heads.1.key.weight: 8192\n",
      "layers.8.attention.heads.1.value.weight: 8192\n",
      "layers.8.attention.heads.2.query.weight: 8192\n",
      "layers.8.attention.heads.2.key.weight: 8192\n",
      "layers.8.attention.heads.2.value.weight: 8192\n",
      "layers.8.attention.heads.3.query.weight: 8192\n",
      "layers.8.attention.heads.3.key.weight: 8192\n",
      "layers.8.attention.heads.3.value.weight: 8192\n",
      "layers.8.attention.heads.4.query.weight: 8192\n",
      "layers.8.attention.heads.4.key.weight: 8192\n",
      "layers.8.attention.heads.4.value.weight: 8192\n",
      "layers.8.attention.heads.5.query.weight: 8192\n",
      "layers.8.attention.heads.5.key.weight: 8192\n",
      "layers.8.attention.heads.5.value.weight: 8192\n",
      "layers.8.attention.heads.6.query.weight: 8192\n",
      "layers.8.attention.heads.6.key.weight: 8192\n",
      "layers.8.attention.heads.6.value.weight: 8192\n",
      "layers.8.attention.heads.7.query.weight: 8192\n",
      "layers.8.attention.heads.7.key.weight: 8192\n",
      "layers.8.attention.heads.7.value.weight: 8192\n",
      "layers.9.attention.heads.0.query.weight: 8192\n",
      "layers.9.attention.heads.0.key.weight: 8192\n",
      "layers.9.attention.heads.0.value.weight: 8192\n",
      "layers.9.attention.heads.1.query.weight: 8192\n",
      "layers.9.attention.heads.1.key.weight: 8192\n",
      "layers.9.attention.heads.1.value.weight: 8192\n",
      "layers.9.attention.heads.2.query.weight: 8192\n",
      "layers.9.attention.heads.2.key.weight: 8192\n",
      "layers.9.attention.heads.2.value.weight: 8192\n",
      "layers.9.attention.heads.3.query.weight: 8192\n",
      "layers.9.attention.heads.3.key.weight: 8192\n",
      "layers.9.attention.heads.3.value.weight: 8192\n",
      "layers.9.attention.heads.4.query.weight: 8192\n",
      "layers.9.attention.heads.4.key.weight: 8192\n",
      "layers.9.attention.heads.4.value.weight: 8192\n",
      "layers.9.attention.heads.5.query.weight: 8192\n",
      "layers.9.attention.heads.5.key.weight: 8192\n",
      "layers.9.attention.heads.5.value.weight: 8192\n",
      "layers.9.attention.heads.6.query.weight: 8192\n",
      "layers.9.attention.heads.6.key.weight: 8192\n",
      "layers.9.attention.heads.6.value.weight: 8192\n",
      "layers.9.attention.heads.7.query.weight: 8192\n",
      "layers.9.attention.heads.7.key.weight: 8192\n",
      "layers.9.attention.heads.7.value.weight: 8192\n",
      "layers.10.attention.heads.0.query.weight: 8192\n",
      "layers.10.attention.heads.0.key.weight: 8192\n",
      "layers.10.attention.heads.0.value.weight: 8192\n",
      "layers.10.attention.heads.1.query.weight: 8192\n",
      "layers.10.attention.heads.1.key.weight: 8192\n",
      "layers.10.attention.heads.1.value.weight: 8192\n",
      "layers.10.attention.heads.2.query.weight: 8192\n",
      "layers.10.attention.heads.2.key.weight: 8192\n",
      "layers.10.attention.heads.2.value.weight: 8192\n",
      "layers.10.attention.heads.3.query.weight: 8192\n",
      "layers.10.attention.heads.3.key.weight: 8192\n",
      "layers.10.attention.heads.3.value.weight: 8192\n",
      "layers.10.attention.heads.4.query.weight: 8192\n",
      "layers.10.attention.heads.4.key.weight: 8192\n",
      "layers.10.attention.heads.4.value.weight: 8192\n",
      "layers.10.attention.heads.5.query.weight: 8192\n",
      "layers.10.attention.heads.5.key.weight: 8192\n",
      "layers.10.attention.heads.5.value.weight: 8192\n",
      "layers.10.attention.heads.6.query.weight: 8192\n",
      "layers.10.attention.heads.6.key.weight: 8192\n",
      "layers.10.attention.heads.6.value.weight: 8192\n",
      "layers.10.attention.heads.7.query.weight: 8192\n",
      "layers.10.attention.heads.7.key.weight: 8192\n",
      "layers.10.attention.heads.7.value.weight: 8192\n",
      "layers.11.attention.heads.0.query.weight: 8192\n",
      "layers.11.attention.heads.0.key.weight: 8192\n",
      "layers.11.attention.heads.0.value.weight: 8192\n",
      "layers.11.attention.heads.1.query.weight: 8192\n",
      "layers.11.attention.heads.1.key.weight: 8192\n",
      "layers.11.attention.heads.1.value.weight: 8192\n",
      "layers.11.attention.heads.2.query.weight: 8192\n",
      "layers.11.attention.heads.2.key.weight: 8192\n",
      "layers.11.attention.heads.2.value.weight: 8192\n",
      "layers.11.attention.heads.3.query.weight: 8192\n",
      "layers.11.attention.heads.3.key.weight: 8192\n",
      "layers.11.attention.heads.3.value.weight: 8192\n",
      "layers.11.attention.heads.4.query.weight: 8192\n",
      "layers.11.attention.heads.4.key.weight: 8192\n",
      "layers.11.attention.heads.4.value.weight: 8192\n",
      "layers.11.attention.heads.5.query.weight: 8192\n",
      "layers.11.attention.heads.5.key.weight: 8192\n",
      "layers.11.attention.heads.5.value.weight: 8192\n",
      "layers.11.attention.heads.6.query.weight: 8192\n",
      "layers.11.attention.heads.6.key.weight: 8192\n",
      "layers.11.attention.heads.6.value.weight: 8192\n",
      "layers.11.attention.heads.7.query.weight: 8192\n",
      "layers.11.attention.heads.7.key.weight: 8192\n",
      "layers.11.attention.heads.7.value.weight: 8192\n",
      "layers.0.ff.net.0.bias: 768\n",
      "layers.1.ff.net.0.bias: 768\n",
      "layers.2.ff.net.0.bias: 768\n",
      "layers.3.ff.net.0.bias: 768\n",
      "layers.4.ff.net.0.bias: 768\n",
      "layers.5.ff.net.0.bias: 768\n",
      "layers.6.ff.net.0.bias: 768\n",
      "layers.7.ff.net.0.bias: 768\n",
      "layers.8.ff.net.0.bias: 768\n",
      "layers.9.ff.net.0.bias: 768\n",
      "layers.10.ff.net.0.bias: 768\n",
      "layers.11.ff.net.0.bias: 768\n",
      "layers.0.attention.combine_heads.bias: 256\n",
      "layers.0.ff.net.2.bias: 256\n",
      "layers.0.norm1.gamma: 256\n",
      "layers.0.norm1.beta: 256\n",
      "layers.0.norm2.gamma: 256\n",
      "layers.0.norm2.beta: 256\n",
      "layers.1.attention.combine_heads.bias: 256\n",
      "layers.1.ff.net.2.bias: 256\n",
      "layers.1.norm1.gamma: 256\n",
      "layers.1.norm1.beta: 256\n",
      "layers.1.norm2.gamma: 256\n",
      "layers.1.norm2.beta: 256\n",
      "layers.2.attention.combine_heads.bias: 256\n",
      "layers.2.ff.net.2.bias: 256\n",
      "layers.2.norm1.gamma: 256\n",
      "layers.2.norm1.beta: 256\n",
      "layers.2.norm2.gamma: 256\n",
      "layers.2.norm2.beta: 256\n",
      "layers.3.attention.combine_heads.bias: 256\n",
      "layers.3.ff.net.2.bias: 256\n",
      "layers.3.norm1.gamma: 256\n",
      "layers.3.norm1.beta: 256\n",
      "layers.3.norm2.gamma: 256\n",
      "layers.3.norm2.beta: 256\n",
      "layers.4.attention.combine_heads.bias: 256\n",
      "layers.4.ff.net.2.bias: 256\n",
      "layers.4.norm1.gamma: 256\n",
      "layers.4.norm1.beta: 256\n",
      "layers.4.norm2.gamma: 256\n",
      "layers.4.norm2.beta: 256\n",
      "layers.5.attention.combine_heads.bias: 256\n",
      "layers.5.ff.net.2.bias: 256\n",
      "layers.5.norm1.gamma: 256\n",
      "layers.5.norm1.beta: 256\n",
      "layers.5.norm2.gamma: 256\n",
      "layers.5.norm2.beta: 256\n",
      "layers.6.attention.combine_heads.bias: 256\n",
      "layers.6.ff.net.2.bias: 256\n",
      "layers.6.norm1.gamma: 256\n",
      "layers.6.norm1.beta: 256\n",
      "layers.6.norm2.gamma: 256\n",
      "layers.6.norm2.beta: 256\n",
      "layers.7.attention.combine_heads.bias: 256\n",
      "layers.7.ff.net.2.bias: 256\n",
      "layers.7.norm1.gamma: 256\n",
      "layers.7.norm1.beta: 256\n",
      "layers.7.norm2.gamma: 256\n",
      "layers.7.norm2.beta: 256\n",
      "layers.8.attention.combine_heads.bias: 256\n",
      "layers.8.ff.net.2.bias: 256\n",
      "layers.8.norm1.gamma: 256\n",
      "layers.8.norm1.beta: 256\n",
      "layers.8.norm2.gamma: 256\n",
      "layers.8.norm2.beta: 256\n",
      "layers.9.attention.combine_heads.bias: 256\n",
      "layers.9.ff.net.2.bias: 256\n",
      "layers.9.norm1.gamma: 256\n",
      "layers.9.norm1.beta: 256\n",
      "layers.9.norm2.gamma: 256\n",
      "layers.9.norm2.beta: 256\n",
      "layers.10.attention.combine_heads.bias: 256\n",
      "layers.10.ff.net.2.bias: 256\n",
      "layers.10.norm1.gamma: 256\n",
      "layers.10.norm1.beta: 256\n",
      "layers.10.norm2.gamma: 256\n",
      "layers.10.norm2.beta: 256\n",
      "layers.11.attention.combine_heads.bias: 256\n",
      "layers.11.ff.net.2.bias: 256\n",
      "layers.11.norm1.gamma: 256\n",
      "layers.11.norm1.beta: 256\n",
      "layers.11.norm2.gamma: 256\n",
      "layers.11.norm2.beta: 256\n"
     ]
    }
   ],
   "source": [
    "# get the number of parameters\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "parameter_to_data_ratio = n_params / len(train_data)\n",
    "print(f\"{parameter_to_data_ratio=}\")\n",
    "\n",
    "parameters = []\n",
    "for name, param in model.named_parameters():\n",
    "    parameters.append({\"name\": name, \"params\": param.numel()})\n",
    "\n",
    "# sort parameters by size\n",
    "sorted_parameters = sorted(parameters, key=lambda x: x[\"params\"], reverse=True)\n",
    "for p in sorted_parameters:\n",
    "    print(f\"{p['name']}: {p['params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/60000 [00:01<8:46:29,  1.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 2.3197550773620605, 'val': 2.316525459289551, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 302/60000 [00:39<3:44:18,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.848213791847229, 'val': 0.8460512161254883, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 602/60000 [01:21<3:43:47,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.7173031568527222, 'val': 0.7209934592247009, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 902/60000 [01:56<5:19:14,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.6550315022468567, 'val': 0.6534883379936218, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1202/60000 [02:41<4:03:28,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.6106777191162109, 'val': 0.6175428032875061, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1502/60000 [03:19<3:17:20,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.5788686871528625, 'val': 0.5822889804840088, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1802/60000 [03:55<3:27:24,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.5583482384681702, 'val': 0.5628054738044739, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2102/60000 [04:38<4:49:24,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.546829879283905, 'val': 0.5460728406906128, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2402/60000 [05:19<4:38:43,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.5330162048339844, 'val': 0.5316081643104553, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2703/60000 [06:00<3:08:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.5252125263214111, 'val': 0.5191770195960999, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3002/60000 [06:45<3:31:22,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.5189629197120667, 'val': 0.5134242177009583, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3302/60000 [07:30<4:20:35,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.5112408995628357, 'val': 0.5056686401367188, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3602/60000 [08:13<3:41:01,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.49557918310165405, 'val': 0.4964991807937622, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3902/60000 [08:54<4:53:53,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.48896706104278564, 'val': 0.4862830638885498, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4203/60000 [09:31<2:40:05,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4893595576286316, 'val': 0.4869172275066376, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4502/60000 [10:09<3:17:47,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4819861948490143, 'val': 0.47948625683784485, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4802/60000 [10:49<4:33:21,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4774918854236603, 'val': 0.4796147644519806, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 5102/60000 [11:31<4:22:14,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4745745062828064, 'val': 0.4859565496444702, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 5403/60000 [12:13<2:37:13,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4691164791584015, 'val': 0.4700319170951843, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 5702/60000 [12:56<4:53:43,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4648531675338745, 'val': 0.47154805064201355, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 6002/60000 [13:32<3:37:03,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4655320942401886, 'val': 0.46875420212745667, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 6302/60000 [14:17<4:30:31,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4568535089492798, 'val': 0.46072298288345337, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 6602/60000 [15:02<3:24:48,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.46624675393104553, 'val': 0.461658239364624, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6902/60000 [15:46<3:19:26,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.45531871914863586, 'val': 0.4583282172679901, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 7202/60000 [16:28<2:41:04,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4588129222393036, 'val': 0.45670628547668457, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 7502/60000 [17:08<4:09:08,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.458290159702301, 'val': 0.4534323811531067, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 7802/60000 [17:52<4:03:46,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.44639691710472107, 'val': 0.4477818012237549, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 8102/60000 [18:35<4:17:40,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.44626837968826294, 'val': 0.4506498873233795, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 8402/60000 [19:17<3:33:36,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.44445979595184326, 'val': 0.4444202184677124, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 8702/60000 [20:06<4:14:47,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4458003342151642, 'val': 0.447415828704834, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 9002/60000 [20:52<3:15:22,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.44905391335487366, 'val': 0.44745221734046936, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 9302/60000 [21:34<4:07:04,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.44019079208374023, 'val': 0.44673067331314087, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 9602/60000 [22:13<3:36:04,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.44448286294937134, 'val': 0.44446924328804016, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 9902/60000 [22:57<3:08:05,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4297686219215393, 'val': 0.4423435628414154, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 10202/60000 [23:31<3:46:14,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.44101792573928833, 'val': 0.4359297752380371, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 10502/60000 [24:12<3:07:02,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4419628381729126, 'val': 0.43952375650405884, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 10802/60000 [24:51<3:34:08,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.43954506516456604, 'val': 0.4355044364929199, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 11102/60000 [25:30<3:05:20,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4369654655456543, 'val': 0.43367886543273926, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 11402/60000 [26:14<2:47:04,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.43440359830856323, 'val': 0.43030232191085815, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 11703/60000 [26:58<2:43:07,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4300914406776428, 'val': 0.43465957045555115, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 12002/60000 [27:41<3:48:48,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.43394455313682556, 'val': 0.4402737319469452, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 12302/60000 [28:28<2:44:14,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4365575909614563, 'val': 0.4296320974826813, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 12602/60000 [29:11<2:44:21,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4342315196990967, 'val': 0.43167099356651306, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 12902/60000 [29:53<3:57:31,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4317355751991272, 'val': 0.4253843426704407, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 13202/60000 [30:35<2:31:45,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.425240695476532, 'val': 0.4290977716445923, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 13502/60000 [31:09<2:50:55,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4270060062408447, 'val': 0.42866334319114685, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 13802/60000 [31:44<2:45:38,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4243968427181244, 'val': 0.4219661056995392, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 14102/60000 [32:28<3:49:19,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.41733676195144653, 'val': 0.4239497184753418, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 14402/60000 [33:16<3:40:48,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.42082151770591736, 'val': 0.4269647002220154, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 14702/60000 [33:52<2:35:57,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.42225274443626404, 'val': 0.4240022301673889, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 15002/60000 [34:32<2:46:51,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4172787070274353, 'val': 0.4206853210926056, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 15302/60000 [35:11<3:06:59,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.41936108469963074, 'val': 0.42085564136505127, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 15602/60000 [35:52<3:36:12,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4218531548976898, 'val': 0.4269405007362366, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 15902/60000 [36:25<2:35:16,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.42026564478874207, 'val': 0.42319679260253906, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 16203/60000 [37:05<2:14:50,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.4207702577114105, 'val': 0.425100713968277, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 16502/60000 [37:44<2:44:49,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tIain': 0.42008715867996216, 'val': 0.4157676100730896, 'kurtosis_avg': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 16551/60000 [37:51<1:39:22,  7.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# l2 regularization\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# l2 = sum(p.pow(2).sum() for p in model.parameters()) / num_params\u001b[39;00m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m+\u001b[39m kurtosis_avg \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.4\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m160\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m steps \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/_tensor.py:513\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/overrides.py:1604\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1604\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "import tqdm\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "\n",
    "for steps in tqdm.tqdm(range(max_iters)):\n",
    "    xb, yb = get_batch('train')\n",
    "    # loss\n",
    "    logits, loss, kurtosis_avg = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    # l2 regularization\n",
    "    # l2 = sum(p.pow(2).sum() for p in model.parameters()) / num_params\n",
    "    loss = loss + kurtosis_avg * 0.4/160\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if steps % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        # wandb.log({\"tIain\": losses['train'].item(), \"val\": losses['val'].item(), \"l2\":l2})\n",
    "        print({\"tIain\": losses['train'].item(), \"val\": losses['val'].item(), \"kurtosis_avg\": kurtosis_avg.item()})\n",
    "\n",
    "losses = estimate_loss(is_last=True)\n",
    "# wandb.log({\"train\": losses['train'].item(), \"val\": losses['val'].item()})\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor(0.4212, device='cuda:0'),\n",
       " 'val': tensor(0.4223, device='cuda:0')}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'tiny-stories-model.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "model.load_state_dict(torch.load('tiny-stories-model.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time Robot was sad. He missed his ball and the lady's car. He wished he could play with the same car, but he was too shy. Instead, he decided to ask the lady if he could help. The lady was very kind and said yes. She helped him take the ball and he was so happy. He thanked the lady and ran to the store to see his ball again. He was so excited and couldn't believe how much he had been with the lady. From that day on, Robot was never shy again and he was never shy again.\"\n",
      "\"Once upon a time, there was a little girl named Lily. She loved to play outside and look at the flowers. One day, her mommy told her they were going to visit a new nation. Lily was so excited!\n",
      "\n",
      "When they got there, Lily saw many people walking with their parents. They were talking about the world and eating yummy food. Lily felt embarrassed because she didn't know what to expect. She watched the people\n"
     ]
    }
   ],
   "source": [
    "print(model.prompt_model(\"Lilly saw a big red apple.\", 200, 0.7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
