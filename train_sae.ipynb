{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 512\n",
      "n_layer: 14\n",
      "n_head: 16\n",
      "n_embd: 512\n",
      "feed_forward_factor: 2.5\n",
      "vocab_size: 8192\n",
      "data_dir: dataset\n",
      "expt_name: restart_good_3hr_search\n",
      "batch_size: 128\n",
      "max_lr: 0.002\n",
      "min_lr: 0.0001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.99\n",
      "warmup_steps: 50\n",
      "max_steps: 60000\n",
      "max_runtime_seconds: 10800\n",
      "weight_decay: 0.12\n",
      "need_epoch_reshuffle: True\n",
      "matmul_precision: high\n",
      "smoke_test: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from sae import TopKSAE, TopKSAEConfig\n",
    "from generate_residuals import EmbeddingGeneratorConfig\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "assert device == 'cuda', \"This notebook is not optimized for CPU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embdconfig = torch.load(\"./residuals/0.pt\")['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingGeneratorConfig(batch_size=512, block_size=512, n_embd=512, ratio_tokens_saved=0.07, residual_layer=10, mb_per_save=2000, save_dir='./residuals/')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embdconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embdconfig\n",
    "\n",
    "saeconfig = TopKSAEConfig(\n",
    "    embedding_size=embdconfig.n_embd,\n",
    "    n_features=32768,\n",
    "    topk=24,\n",
    "    lr = 1e-3,\n",
    "    batch_size=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = TopKSAE(saeconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 14 files\n",
      "Testing on 2 files\n"
     ]
    }
   ],
   "source": [
    "residuals_dir = embdconfig.save_dir\n",
    "ratio_train=0.9\n",
    "\n",
    "residuals_files = [os.path.join(residuals_dir, f) for f in os.listdir(residuals_dir)]\n",
    "\n",
    "train_files = residuals_files[:int(len(residuals_files)*ratio_train)]\n",
    "test_files = residuals_files[int(len(residuals_files)*ratio_train):]\n",
    "\n",
    "print(f\"Training on {len(train_files)} files\")\n",
    "print(f\"Testing on {len(test_files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./residuals/15.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 35.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3685932159423828\n",
      "Loading ./residuals/14.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 35.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3354792892932892\n",
      "Loading ./residuals/13.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 35.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32165712118148804\n",
      "Loading ./residuals/12.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 35.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31672143936157227\n",
      "Loading ./residuals/11.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 34.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3071986138820648\n",
      "Loading ./residuals/10.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 34.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3015247583389282\n",
      "Loading ./residuals/9.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 34.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30244624614715576\n",
      "Loading ./residuals/8.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:14<00:00, 34.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30095475912094116\n",
      "Loading ./residuals/7.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 34.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2984688878059387\n",
      "Loading ./residuals/6.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 34.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2971307039260864\n",
      "Loading ./residuals/5.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 34.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2946024239063263\n",
      "Loading ./residuals/4.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 34.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29326707124710083\n",
      "Loading ./residuals/3.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:13<00:00, 34.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.293413907289505\n",
      "Loading ./residuals/2.pt\n",
      "torch.Size([1963450, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:14<00:00, 34.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2851043939590454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(sae.parameters(), lr=sae.config.lr)\n",
    "\n",
    "# Run your forward pass\n",
    "for f in train_files:\n",
    "    print(f\"Loading {f}\")\n",
    "    data = torch.load(f)['residuals']\n",
    "    data = data[torch.randperm(data.shape[0])]\n",
    "    data = data.to(torch.float32)\n",
    "    # b a t c h data\n",
    "    print(data.shape)\n",
    "    data = data[:data.shape[0]//sae.config.batch_size*sae.config.batch_size] # cut off the last (incomplete) batch\n",
    "    data = data.view(-1, sae.config.batch_size, sae.config.embedding_size)\n",
    "    for batch in tqdm(data):\n",
    "        sae_out = sae(batch)\n",
    "        loss = sae_out['mse']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model': sae.state_dict(),\n",
    "            'config': sae.config}, \n",
    "            'saes/sae.pt')\n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
