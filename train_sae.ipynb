{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from sae import TopKSAE, TopKSAEConfig\n",
    "from generate_residuals import EmbeddingGeneratorConfig\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "assert device == 'cuda', \"This notebook is not optimized for CPU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embdconfig = torch.load(\"./small_residuals/0.pt\")['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingGeneratorConfig(batch_size=512, block_size=512, n_embd=384, ratio_tokens_saved=0.07, residual_layer=8, mb_per_save=2000, save_dir='./small_residuals')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embdconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embdconfig\n",
    "\n",
    "saeconfig = TopKSAEConfig(\n",
    "    embedding_size=embdconfig.n_embd,\n",
    "    n_features=32768//2,\n",
    "    topk=24,\n",
    "    lr = 1e-3,\n",
    "    batch_size=4096,\n",
    "    latent_bias=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = TopKSAE(saeconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 11 files\n",
      "Testing on 2 files\n"
     ]
    }
   ],
   "source": [
    "residuals_dir = embdconfig.save_dir\n",
    "ratio_train=0.9\n",
    "\n",
    "residuals_files = [os.path.join(residuals_dir, f) for f in os.listdir(residuals_dir)]\n",
    "\n",
    "train_files = residuals_files[:int(len(residuals_files)*ratio_train)]\n",
    "test_files = residuals_files[int(len(residuals_files)*ratio_train):]\n",
    "\n",
    "print(f\"Training on {len(train_files)} files\")\n",
    "print(f\"Testing on {len(test_files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./small_residuals/12.pt\n",
      "torch.Size([1394600, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [00:03<00:00, 106.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5932797193527222\n",
      "Loading ./small_residuals/11.pt\n",
      "torch.Size([2605700, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:05<00:00, 113.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40341418981552124\n",
      "Loading ./small_residuals/10.pt\n",
      "torch.Size([2605700, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:05<00:00, 114.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36649155616760254\n",
      "Loading ./small_residuals/9.pt\n",
      "torch.Size([2605700, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:05<00:00, 113.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35675835609436035\n",
      "Loading ./small_residuals/8.pt\n",
      "torch.Size([2605700, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:05<00:00, 113.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34561464190483093\n",
      "Loading ./small_residuals/7.pt\n",
      "torch.Size([2605700, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:05<00:00, 113.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34066280722618103\n",
      "Loading ./small_residuals/6.pt\n",
      "torch.Size([2605700, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:05<00:00, 113.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33527040481567383\n",
      "Loading ./small_residuals/5.pt\n",
      "torch.Size([2605700, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:05<00:00, 113.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32978227734565735\n",
      "Loading ./small_residuals/4.pt\n",
      "torch.Size([2605700, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:05<00:00, 112.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3294694423675537\n",
      "Loading ./small_residuals/3.pt\n",
      "torch.Size([2605700, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:05<00:00, 113.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3307689428329468\n",
      "Loading ./small_residuals/2.pt\n",
      "torch.Size([2605700, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:05<00:00, 113.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3219376504421234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(sae.parameters(), lr=sae.config.lr)\n",
    "\n",
    "# Run your forward pass\n",
    "for f in train_files:\n",
    "    print(f\"Loading {f}\")\n",
    "    data = torch.load(f)['residuals']\n",
    "    data = data[torch.randperm(data.shape[0])]\n",
    "    data = data.to(torch.float32)\n",
    "    # b a t c h data\n",
    "    print(data.shape)\n",
    "    data = data[:data.shape[0]//sae.config.batch_size*sae.config.batch_size] # cut off the last (incomplete) batch\n",
    "    data = data.view(-1, sae.config.batch_size, sae.config.embedding_size)\n",
    "    for batch in tqdm(data):\n",
    "        sae_out = sae(batch)\n",
    "        loss = sae_out['mse']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model': sae.state_dict(),\n",
    "            'config': sae.config}, \n",
    "            'saes/sae_small_16k_features.pt')\n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
