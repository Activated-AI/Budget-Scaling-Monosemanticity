{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7567acb10640>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt import load_model_from_checkpoint, GPT, GPTConfig, generate, preprocess_tokens_from_huggingface\n",
    "import transformers\n",
    "import torch\n",
    "from dataclasses import dataclass, fields\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "assert device == 'cuda', \"This notebook is not optimized for CPU\"\n",
    "torch.autograd.set_grad_enabled(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_from_checkpoint(\"./llms/50m_llm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = transformers.AutoTokenizer.from_pretrained('activated-ai/tiny-stories-8k-tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Once upon a time, there was a big bird named Max. Max was very hungry and wanted to eat something yummy. So, he decided to go on an adventure. He flew high in the sky and saw many places. \\n\\nAs he was flying, he saw a big tree with lots of fruits. Max knew that he could eat the fruits if he was very careful. He didn't want to be scared or make any threats. Max flew down and ate some grapes. \\n\\nAfter\",\n",
       " 'Once upon a time there was a little girl named Sarah. She had ten long fingers which made her feel so much love.\\n\\nOne day, Sarah went out with her mommy to the park. While they were there, Sarah saw something that made her eyes grow: a big, soft, pink teddy bear. She knew she had to have it.\\n\\nSo Sarah asked her mommy if she could have the teddy bear. Her mommy said yes, so Sarah was so happy! She hugged the']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, enc, \"Once upon a time\", 100, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping token preprocessing for validation : using cache ./datasets/validation.pt\n",
      "skipping token preprocessing for train : using cache ./datasets/train.pt\n"
     ]
    }
   ],
   "source": [
    "preprocess_tokens_from_huggingface(\"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  torch.load(\"datasets/train.pt\", map_location=device)\n",
    "train = train.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EmbeddingGeneratorConfig:\n",
    "    batch_size: int = 512\n",
    "    block_size: int = 512\n",
    "    n_embd: int = 512\n",
    "    ratio_tokens_saved: float = 0.07\n",
    "    residual_layer: int = 6\n",
    "    mb_per_save: int = 2000\n",
    "    save_dir: float = \"./residuals/\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingconfig = EmbeddingGeneratorConfig(\n",
    "    batch_size=512,\n",
    "    block_size=model.config.block_size,\n",
    "    n_embd=model.config.n_embd,\n",
    "    residual_layer=round(model.config.n_layer*0.65)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed tokens from dataset: 130959\n"
     ]
    }
   ],
   "source": [
    "dataset_remainder = train.shape[0] % (embeddingconfig.block_size * embeddingconfig.batch_size)\n",
    "dataset_length = train.shape[0] - dataset_remainder\n",
    "print(\"removed tokens from dataset:\", dataset_remainder)\n",
    "batches = train[:dataset_length].view(-1, embeddingconfig.batch_size, embeddingconfig.block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_embd_to_mb(n):\n",
    "    mb_per_embedding = embeddingconfig.n_embd * 2 / 1_000_000\n",
    "    return mb_per_embedding * n\n",
    "\n",
    "def mb_to_n_embd(mb):\n",
    "    mb_per_embedding = embeddingconfig.n_embd * 2 / 1_000_000\n",
    "    return int(mb / mb_per_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated storage on disk (MB): 33447.057408\n"
     ]
    }
   ],
   "source": [
    "print(\"estimated storage on disk (MB):\", n_embd_to_mb(int(batches.shape[0]*embeddingconfig.ratio_tokens_saved*embeddingconfig.block_size*embeddingconfig.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.5000, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(5.5).to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated storage on disk (MB): 33447.057408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [19:52<00:00,  1.49it/s] \n"
     ]
    }
   ],
   "source": [
    "#@torch.no_grad()\n",
    "\n",
    "save_residuals_buffer = []\n",
    "global_token_starts_buffer = []\n",
    "global_context_window_starts_buffer = []\n",
    "\n",
    "save_counter = 0\n",
    "\n",
    "os.makedirs(embeddingconfig.save_dir, exist_ok=True)\n",
    "\n",
    "print(\"estimated storage on disk (MB):\", n_embd_to_mb(int(batches.shape[0]*embeddingconfig.ratio_tokens_saved*embeddingconfig.block_size*embeddingconfig.batch_size)))\n",
    "\n",
    "for batch_index, batch in enumerate(tqdm(batches)):\n",
    "    tokens_per_batch = embeddingconfig.batch_size * embeddingconfig.block_size\n",
    "    global_token_start_pos = batch_index * embeddingconfig.batch_size * embeddingconfig.block_size\n",
    "    local_idxs = torch.randperm(tokens_per_batch)[:int(tokens_per_batch * embeddingconfig.ratio_tokens_saved)]\n",
    "    global_idxs = local_idxs + global_token_start_pos\n",
    "    global_window_starts = global_idxs - global_idxs % embeddingconfig.block_size\n",
    "    global_context_window_starts_buffer += global_window_starts.tolist()\n",
    "    global_token_starts_buffer += global_idxs.tolist()\n",
    "    \n",
    "    \n",
    "    model_out = model(batch, return_layer_embs = embeddingconfig.residual_layer).view(-1, embeddingconfig.n_embd)[local_idxs, :]\n",
    "    save_residuals_buffer.append(model_out)\n",
    "    num_embeddings_in_buffer = embeddingconfig.batch_size * embeddingconfig.block_size * len(save_residuals_buffer) * embeddingconfig.ratio_tokens_saved\n",
    "    if n_embd_to_mb(num_embeddings_in_buffer) > embeddingconfig.mb_per_save:\n",
    "        residuals_tensor = torch.cat(save_residuals_buffer)\n",
    "        torch.save({\n",
    "                    \"residuals\": residuals_tensor.to(torch.bfloat16),\n",
    "                    \"token_idxs\": global_token_starts_buffer,\n",
    "                    \"context_window_starts\": global_context_window_starts_buffer,\n",
    "                    \"config\": embeddingconfig\n",
    "                    },\n",
    "                    f\"./{embeddingconfig.save_dir}/{save_counter}.pt\",)\n",
    "        save_counter += 1\n",
    "        save_residuals_buffer = []\n",
    "        global_token_starts_buffer = []\n",
    "        global_context_window_starts_buffer = []\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.9688e+00,  1.8438e+00,  1.3672e+00, -2.1094e+00, -2.0938e+00,\n",
       "        -1.1133e-01, -5.4688e-01, -1.1133e-01,  1.6235e-02,  1.2969e+00,\n",
       "        -1.1562e+00,  7.1875e-01, -1.4141e+00,  7.4219e-01,  4.4531e-01,\n",
       "        -1.0234e+00,  1.2266e+00, -1.4258e-01,  7.1094e-01, -1.4258e-01,\n",
       "        -3.2031e-01,  3.0469e-01,  1.3281e-01,  5.3906e-01,  2.5781e-01,\n",
       "         1.1875e+00, -5.2344e-01, -1.1641e+00, -3.9648e-01,  1.6953e+00,\n",
       "         1.9238e-01, -1.1172e+00,  1.0986e-01, -2.1387e-01, -6.0547e-01,\n",
       "        -2.8687e-02,  4.4531e-01, -1.1484e+00,  6.3672e-01, -4.3945e-01,\n",
       "        -2.1289e-01,  7.5000e+00, -4.5703e-01, -6.6016e-01,  2.7969e+00,\n",
       "        -3.5352e-01,  1.0312e+00, -5.5078e-01, -9.0820e-02,  4.8828e-02,\n",
       "         1.6562e+00,  9.9219e-01, -1.3281e+00,  1.2422e+00,  1.2656e+00,\n",
       "         1.3594e+00, -8.1250e-01,  2.1094e+00,  3.5742e-01, -3.5742e-01,\n",
       "        -5.5078e-01,  1.0547e+00,  1.8750e+00, -4.1016e-01, -1.0889e-01,\n",
       "        -9.5703e-01, -5.7422e-01,  7.5195e-02, -2.6758e-01, -1.1172e+00,\n",
       "        -1.1953e+00,  1.7090e-01, -2.4219e-01,  9.9609e-01,  8.7891e-02,\n",
       "        -8.0078e-01, -5.0781e-01, -1.5723e-01, -6.6797e-01, -4.4922e-01,\n",
       "        -5.0000e-01,  2.3560e-02, -2.5586e-01, -1.0986e-01, -1.2891e+00,\n",
       "        -1.0391e+00, -1.0312e+00, -1.7500e+00, -8.5547e-01, -5.3125e-01,\n",
       "        -8.7891e-01, -1.3438e+00,  1.3984e+00, -1.7891e+00, -9.3750e-01,\n",
       "         7.1875e-01,  1.7266e+00, -9.2188e-01,  1.4375e+00,  8.9062e-01,\n",
       "         3.3203e-01,  9.9609e-01,  1.7285e-01, -1.5000e+00, -1.6406e+00,\n",
       "        -1.1797e+00, -4.3359e-01, -3.7695e-01, -1.2695e-02,  1.9062e+00,\n",
       "         9.1797e-01, -1.1641e+00,  2.5513e-02, -1.4531e+00, -1.7266e+00,\n",
       "        -9.4531e-01, -8.0859e-01,  1.3672e-02, -2.3926e-01, -4.0039e-01,\n",
       "         1.9824e-01,  2.6733e-02,  1.1016e+00, -9.6094e-01, -1.2031e+00,\n",
       "         1.0938e+00, -2.5586e-01, -7.0312e-01, -3.1641e-01,  7.8613e-02,\n",
       "         3.4375e-01, -1.3125e+00,  1.5234e-01,  5.2246e-02,  1.0469e+00,\n",
       "        -9.8828e-01, -1.2422e+00,  8.1055e-02, -1.1406e+00, -1.6406e+00,\n",
       "        -1.9043e-01, -1.3672e+00,  6.5234e-01, -9.3262e-02, -4.0820e-01,\n",
       "        -7.1484e-01, -6.4062e-01, -1.6406e+00, -3.2031e-01, -1.5430e-01,\n",
       "        -1.0703e+00,  3.0273e-01,  7.1875e-01, -1.0312e+00, -3.9648e-01,\n",
       "         4.4922e-01,  1.6992e-01, -1.6113e-01, -1.3770e-01,  4.2578e-01,\n",
       "         2.3125e+00, -1.9453e+00, -1.5078e+00, -1.3047e+00,  9.6094e-01,\n",
       "        -3.6914e-01, -1.3359e+00,  4.7119e-02, -1.8875e+01,  3.0469e-01,\n",
       "        -7.0312e-01, -4.0234e-01, -8.3594e-01,  1.7500e+00,  7.8906e-01,\n",
       "        -1.1719e+00, -1.3203e+00, -5.0391e-01, -1.4609e+00,  1.0156e+00,\n",
       "         9.6484e-01, -1.4297e+00, -1.0938e+00, -2.4375e+00,  9.5703e-01,\n",
       "         1.0352e-01, -1.1797e+00, -1.8984e+00, -3.8477e-01, -7.8125e-01,\n",
       "         2.7539e-01,  1.6309e-01, -1.5859e+00,  8.6328e-01, -1.4219e+00,\n",
       "         3.8086e-01,  1.0469e+00,  3.5156e-01,  2.7344e+00,  4.2773e-01,\n",
       "         3.2812e+00,  7.3828e-01,  1.8750e+00, -5.3516e-01, -2.7734e-01,\n",
       "         1.0312e+00,  4.1602e-01, -8.0859e-01,  3.2617e-01,  1.1953e+00,\n",
       "        -1.1953e+00,  1.3047e+00,  6.7188e-01, -2.3438e+00, -1.4746e-01,\n",
       "        -9.0625e-01,  1.3281e+00,  3.7695e-01,  2.5156e+00,  1.1797e+00,\n",
       "        -6.9922e-01,  2.3633e-01, -1.7969e+00,  2.2266e-01, -1.4062e-01,\n",
       "        -3.3594e-01, -6.4844e-01, -1.5430e-01, -4.0234e-01,  2.0801e-01,\n",
       "         1.7656e+00,  4.5117e-01,  3.0156e+00, -6.7188e-01,  2.1875e+00,\n",
       "         2.8906e-01, -1.9727e-01,  1.5391e+00,  6.0547e-02, -1.0938e+00,\n",
       "         8.6328e-01, -8.6719e-01, -7.8516e-01, -3.8477e-01,  1.2500e+00,\n",
       "        -7.6562e-01,  8.0078e-01, -6.9531e-01, -1.0859e+00,  8.5156e-01,\n",
       "         2.2812e+00, -1.1250e+00,  7.1484e-01, -4.1602e-01,  1.1797e+00,\n",
       "         9.8047e-01,  8.0566e-02,  9.2285e-02, -4.4531e-01,  3.6133e-01,\n",
       "         1.0156e-01, -9.1406e-01, -2.0625e+00, -1.8848e-01, -3.6914e-01,\n",
       "         2.6953e-01,  1.7188e-01,  7.3828e-01,  1.6953e+00, -1.3125e+00,\n",
       "         6.5234e-01, -5.5078e-01,  6.9922e-01,  8.7500e-01,  2.5146e-02,\n",
       "        -7.6953e-01,  1.1719e+00,  1.2500e+00,  1.7344e+00, -8.4766e-01,\n",
       "         2.0938e+00,  6.0938e-01,  8.5547e-01,  7.0312e-01, -5.1953e-01,\n",
       "         6.1328e-01,  1.7656e+00, -7.0801e-02, -1.0312e+00,  2.1719e+00,\n",
       "        -7.3828e-01,  1.0000e+00, -9.7656e-01, -5.6641e-01,  1.4922e+00,\n",
       "         1.4609e+00,  1.4219e+00,  9.1016e-01,  8.4375e-01, -6.8750e-01,\n",
       "        -6.5918e-02,  7.3047e-01,  5.1172e-01, -3.6523e-01, -1.1172e+00,\n",
       "         1.0469e+00, -9.1797e-01, -1.5859e+00,  1.1094e+00, -1.5000e+00,\n",
       "         8.6719e-01,  5.8203e-01, -2.0781e+00,  3.6523e-01,  8.6719e-01,\n",
       "        -3.4180e-01, -6.7871e-02, -2.8906e-01,  5.3906e-01, -2.9492e-01,\n",
       "         1.2891e+00,  7.1875e-01,  2.2656e+00, -6.0547e-01, -8.4766e-01,\n",
       "        -1.0234e+00,  1.1172e+00,  2.0117e-01, -6.1328e-01,  4.1602e-01,\n",
       "         1.1094e+00, -6.4844e-01, -1.5156e+00,  1.0547e+00, -7.9297e-01,\n",
       "        -3.4943e-03, -7.5391e-01,  1.5391e+00, -3.1836e-01, -1.0156e+00,\n",
       "        -1.5000e+00,  1.8359e-01,  1.1172e+00, -5.5078e-01,  1.6992e-01,\n",
       "         2.1875e-01, -5.3516e-01,  1.4141e+00, -1.0625e+00,  9.8828e-01,\n",
       "        -1.0352e-01,  9.8438e-01,  5.4297e-01, -1.3359e+00, -1.9922e-01,\n",
       "        -1.3281e+00,  1.9375e+00,  1.1250e+00,  1.0234e+00,  9.0625e-01,\n",
       "        -7.9688e-01,  1.2656e+00, -4.4336e-01, -1.3125e+00, -1.4062e+00,\n",
       "         1.5703e+00,  4.5703e-01, -2.2754e-01,  2.2852e-01, -1.0469e+00,\n",
       "        -1.1250e+00,  5.5078e-01, -4.8633e-01, -1.2158e-01,  1.5938e+00,\n",
       "        -1.5039e-01,  5.3906e-01, -1.5938e+00,  4.0820e-01,  2.0156e+00,\n",
       "        -1.6406e+00, -1.6797e+00, -8.7891e-02, -9.8438e-01, -1.5078e+00,\n",
       "         2.9102e-01,  4.1992e-01, -5.6641e-01,  1.2891e+00,  1.0703e+00,\n",
       "        -1.3281e-01,  1.2969e+00, -2.4844e+00,  8.1641e-01,  2.5156e+00,\n",
       "        -3.9648e-01,  3.7305e-01,  8.5938e-01, -9.3750e-02, -5.0781e-01,\n",
       "        -8.4375e-01,  1.5869e-02, -5.8594e-01, -7.2266e-01,  6.2891e-01,\n",
       "         1.4141e+00,  1.1953e+00, -4.5312e-01,  3.7500e-01, -9.4531e-01,\n",
       "         1.6094e+00,  8.3594e-01, -1.3750e+00,  1.9629e-01, -1.0000e+00,\n",
       "         2.8516e-01,  2.2969e+00, -2.0156e+00,  9.5703e-02,  1.1016e+00,\n",
       "        -7.1875e-01,  9.5312e-01,  3.0781e+00,  6.9531e-01, -8.6328e-01,\n",
       "        -2.4219e+00,  1.0156e+00,  1.5703e+00, -7.5000e-01, -4.5117e-01,\n",
       "         6.1719e-01, -3.9062e-01,  2.0469e+00, -8.7891e-01, -6.4844e-01,\n",
       "        -1.1250e+00,  1.3828e+00,  3.6523e-01, -1.1016e+00,  1.6875e+00,\n",
       "        -4.0039e-01,  2.6875e+00, -2.6367e-01,  1.9219e+00,  1.1719e+00,\n",
       "         1.1016e+00,  1.1719e+00,  2.3047e-01,  2.1094e-01, -5.7422e-01,\n",
       "        -3.6133e-01, -2.5000e-01, -2.1250e+00,  1.3281e+00, -1.6406e+00,\n",
       "        -1.1094e+00,  1.6953e+00,  3.8477e-01,  7.0703e-01, -7.5000e-01,\n",
       "         1.7109e+00,  9.2969e-01,  1.8438e+00,  6.3672e-01, -1.4297e+00,\n",
       "         5.4199e-02, -2.3828e-01, -1.1641e+00,  5.5469e-01, -5.5859e-01,\n",
       "        -8.1641e-01,  1.6250e+00, -3.6328e-01,  1.0469e+00,  1.2598e-01,\n",
       "         1.7969e+00, -1.9922e+00,  7.1289e-02, -9.7266e-01,  3.7500e-01,\n",
       "        -1.1094e+00,  1.2988e-01,  3.0469e-01,  4.8633e-01,  3.5938e-01,\n",
       "        -2.8750e+00,  5.3516e-01, -1.5781e+00, -2.2705e-02, -4.5508e-01,\n",
       "         6.9531e-01, -9.8047e-01, -8.5938e-01,  1.4219e+00, -1.1641e+00,\n",
       "         4.7266e-01, -1.2812e+00,  6.6016e-01, -1.0469e+00, -9.8438e-01,\n",
       "        -3.8867e-01,  1.8457e-01, -1.1328e+00, -9.8047e-01, -1.1641e+00,\n",
       "        -3.5156e-01,  3.2031e-01,  1.1328e+00, -6.6797e-01,  6.4844e-01,\n",
       "        -2.6953e-01,  1.0625e+00], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"./residuals/2.pt\")['residuals'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
