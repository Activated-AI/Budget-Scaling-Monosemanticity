{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:e5gqjrit) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9681ad9b8a43c395ad6295d47ba299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.012 MB uploaded\\r'), FloatProgress(value=0.36583816405939806, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-mountain-21</strong> at: <a href='https://wandb.ai/llmhacking/scaling-monosemanticity/runs/e5gqjrit' target=\"_blank\">https://wandb.ai/llmhacking/scaling-monosemanticity/runs/e5gqjrit</a><br/> View project at: <a href='https://wandb.ai/llmhacking/scaling-monosemanticity' target=\"_blank\">https://wandb.ai/llmhacking/scaling-monosemanticity</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240729_220706-e5gqjrit/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:e5gqjrit). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/diegocaples/Code/ai/implementations-experiments/scaling-monosemanticity no kurtosis/wandb/run-20240729_220735-j88jnaf5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/llmhacking/scaling-monosemanticity/runs/j88jnaf5' target=\"_blank\">ethereal-yogurt-22</a></strong> to <a href='https://wandb.ai/llmhacking/scaling-monosemanticity' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/llmhacking/scaling-monosemanticity' target=\"_blank\">https://wandb.ai/llmhacking/scaling-monosemanticity</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/llmhacking/scaling-monosemanticity/runs/j88jnaf5' target=\"_blank\">https://wandb.ai/llmhacking/scaling-monosemanticity/runs/j88jnaf5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/llmhacking/scaling-monosemanticity/runs/j88jnaf5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7cea24905520>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----- imports --------\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import wandb\n",
    "import os\n",
    "import tokenizers\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "assert device == 'cuda', \"This notebook is not optimized for CPU\"\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    # 'sae_size': 2**18,\n",
    "     'sae_size': 2**14,\n",
    "    \"sae_learning_rate\": 5e-5,\n",
    "    \"sae_sparsity_penalty\": 250,\n",
    "    \"model_embedding_layer\": 6,\n",
    "    \"eval_interval\": 500,\n",
    "    \"max_iters\": 60000, \n",
    "    \"H\": 32, # hidden dimension size\n",
    "    \"B\": 64,\n",
    "    \"T\": 256,\n",
    "    \"C\": 256,\n",
    "    \"feedforward_factor\": 3,\n",
    "    \"n_heads\": 8,\n",
    "    \"n_layers\": 12,\n",
    "    \"tokenizer_vocab_size\": 2**13,\n",
    "    \"git_hash\": os.popen(\"git rev-parse HEAD\").read().strip()\n",
    "}\n",
    "\n",
    "# initial\n",
    "for k,v in config.items():\n",
    "    locals ()[k] = v\n",
    "\n",
    "\n",
    "# wandb.init(\n",
    "#    project = \"scaling-monosemanticity\",\n",
    "#    config = config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoEncoder(nn.Module):\n",
    "    def __init__(self, activations_dim, sparse_dim):\n",
    "        super().__init__()\n",
    "        self.activations_dim = activations_dim\n",
    "        encoder_weight = torch.randn(activations_dim, sparse_dim)\n",
    "        decoder_weight = torch.randn(sparse_dim, activations_dim)\n",
    "        self.encoder_bias = nn.Parameter(torch.zeros(sparse_dim))\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(activations_dim))\n",
    "        self.sparse_dim = sparse_dim\n",
    "        self.sparsity_penalty = sae_sparsity_penalty\n",
    "\n",
    "        # set the encoder_weight to have the activations dim to be normalized to have l2 norm randomly between 0.05 and 1\n",
    "        direction_lengths = torch.rand(sparse_dim) * 0.95 + 0.05\n",
    "        # normalize the encoder_weight along columns (dim -2) to have l2 norm of 1\n",
    "        encoder_weight = F.normalize(encoder_weight, p=2, dim=0)\n",
    "        # multiply the column norms by the direction_lengths\n",
    "        encoder_weight = encoder_weight * direction_lengths\n",
    "        # make the decoder weight be the transpose of the encoder_weight\n",
    "        decoder_weight = torch.transpose(encoder_weight, 0, 1)\n",
    "\n",
    "        self.encoder_weight = nn.Parameter(encoder_weight)\n",
    "        self.decoder_weight = nn.Parameter(decoder_weight)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # preprocessing normalization\n",
    "        # now on average any embedding has euclidian length 1\n",
    "\n",
    "        encoded = F.relu(x @ self.encoder_weight + self.encoder_bias) # all act. are positive\n",
    "        decoded = encoded @ self.decoder_weight + self.decoder_bias\n",
    "\n",
    "        reconstruction_l2_loss = F.mse_loss(x, decoded)\n",
    "\n",
    "        # every row in the tall decoder matrix\n",
    "        # is the \"sum\" of the total influence of a feature on the output\n",
    "        # the l2 norm of that row is the \"influence\" of that feature on that output\n",
    "        # calculate that, store as row\n",
    "        decoder_l2 = torch.linalg.norm(self.decoder_weight, dim=-1)\n",
    "        # the feature activation is the sparse activation * it's influence on output\n",
    "        feature_activations = (encoded) * decoder_l2\n",
    "        # sum of feature activations\n",
    "        # divide by the batch size * sequence length\n",
    "        # should work if there is no batch dimension\n",
    "        if x.ndim == 3:\n",
    "            batch_dim, sequence_dim, _ = x.shape\n",
    "        elif x.ndim == 2:\n",
    "            batch_dim = 1\n",
    "            sequence_dim, _ = x.shape\n",
    "        elif x.ndim == 1:\n",
    "            batch_dim = 1\n",
    "            sequence_dim = 1\n",
    "        else:\n",
    "            raise ValueError(f\"x has {x.ndim} dimensions, but it should have 1, 2, or 3\")\n",
    "        \n",
    "        sparsity_loss = torch.sum(feature_activations) * self.sparsity_penalty / (batch_dim * sequence_dim * self.sparse_dim)\n",
    "\n",
    "        total_loss = reconstruction_l2_loss + sparsity_loss\n",
    "\n",
    "        return {\"encoded\": encoded, \"decoded\": decoded, 'feature_activations': feature_activations, \"reconstruction_loss\": reconstruction_l2_loss, \"sparsity_loss\": sparsity_loss, \"total_loss\": total_loss}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sae = SparseAutoEncoder(C, sae_size)\n",
    "optimizer = torch.optim.Adam(sae.parameters(), lr=sae_learning_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 8405248\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of parameters\n",
    "total_params = sum(p.numel() for p in sae.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensor(filepath):\n",
    "    # load the .pt tensor\n",
    "    tensor = torch.load(filepath)\n",
    "    tensor = torch.cat(tensor, dim=0)\n",
    "    tensor = tensor.to(device)\n",
    "    return tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reconstruction_loss': 2926.012451171875,\n",
       " 'sparsity_loss': 179.74524688720703,\n",
       " 'total_loss': 3105.7576904296875}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_sae_loss(eval_iters, tensor):\n",
    "    sae_loss = 0\n",
    "    sae_sparsity_loss = 0\n",
    "    sae_reconstruction_loss = 0\n",
    "    count = 0\n",
    "    for i in range(0, eval_iters, B):\n",
    "        count += 1\n",
    "        start = i\n",
    "        end = i+B\n",
    "        assert tensor.shape[0] >= end, f\"too many eval_iters\"\n",
    "        sample = tensor[start:end]\n",
    "        sae_output = sae(sample)\n",
    "        sae_loss += sae_output['total_loss'].item()\n",
    "        sae_sparsity_loss += sae_output['sparsity_loss'].item()\n",
    "        sae_reconstruction_loss += sae_output['reconstruction_loss'].item()\n",
    "    avg_loss = sae_loss/count\n",
    "    avg_sparsity_loss = sae_sparsity_loss/count\n",
    "    avg_reconstruction_loss = sae_reconstruction_loss/count\n",
    "    return {\"reconstruction_loss\": avg_reconstruction_loss, \"sparsity_loss\": avg_sparsity_loss, \"total_loss\": avg_loss}\n",
    "    \n",
    "\n",
    "\n",
    "estimate_sae_loss(100, load_tensor(\"residuals/residuals_train_1.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = []\n",
    "val_filepaths = []\n",
    "for file in os.listdir(f'residuals'):\n",
    "    if file.startswith(f\"residuals_train\"):\n",
    "        train_filepaths.append(f\"residuals/{file}\")\n",
    "    elif file.startswith(f\"residuals_val\"):\n",
    "        val_filepaths.append(f\"residuals/{file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51187/51187 [01:49<00:00, 469.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51187/51187 [01:53<00:00, 452.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51187/51187 [01:33<00:00, 547.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51187/51187 [01:32<00:00, 553.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51187/51187 [01:36<00:00, 528.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51187/51187 [01:48<00:00, 471.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44865/44865 [01:23<00:00, 537.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51187/51187 [01:34<00:00, 539.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51187/51187 [02:02<00:00, 416.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51187/51187 [01:40<00:00, 509.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 5034/51187 [00:12<01:50, 418.13it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m sae_sparsity_loss \u001b[38;5;241m=\u001b[39m sae_output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparsity_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m sae_reconstruction_loss \u001b[38;5;241m+\u001b[39m sae_sparsity_loss\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m logging_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/_tensor.py:513\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/overrides.py:1604\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1604\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(sae.parameters(), lr=sae_learning_rate)\n",
    "num_epochs = 1\n",
    "logging_interval = 50000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for filepath in train_filepaths:\n",
    "        val_residuals_tensor = load_tensor(random.choice(val_filepaths))\n",
    "        print(f\"val loss on next datafile\")\n",
    "        val_data = estimate_sae_loss(1000, val_residuals_tensor)# keys: reconstruction_loss, sparsity_loss, total_loss\n",
    "        # wandb.log({\"val_reconstruction_loss\": val_data['reconstruction_loss'], \"val_sparsity_loss\": val_data['sparsity_loss'], \"val_total_loss\": val_data['total_loss']})\n",
    "        del val_residuals_tensor\n",
    "        residuals_tensor = load_tensor(filepath)\n",
    "        print(f\"train loss on next datafile\")\n",
    "        train_data = estimate_sae_loss(1000, residuals_tensor)# keys: reconstruction_loss, sparsity_loss, total_loss\n",
    "        # wandb.log({\"train_reconstruction_loss\": train_data['reconstruction_loss'], \"train_sparsity_loss\": train_data['sparsity_loss'], \"train_total_loss\": train_data['total_loss']})\n",
    "        print(f\"training on {filepath}\")\n",
    "\n",
    "        for i in tqdm.tqdm(range(0, residuals_tensor.shape[0]-B, B)):\n",
    "            start = i\n",
    "            end = i+B\n",
    "            assert residuals_tensor.shape[0] >= end, f\"too many train samples\"\n",
    "            sample = residuals_tensor[start:end]\n",
    "            optimizer.zero_grad()\n",
    "            sae_output = sae(sample)\n",
    "            sae_reconstruction_loss = sae_output['reconstruction_loss']\n",
    "            sae_sparsity_loss = sae_output['sparsity_loss']\n",
    "            total_loss = sae_reconstruction_loss + sae_sparsity_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % logging_interval == 0:\n",
    "                pass\n",
    "                # wandb.log({\"frequent_reconstruction_loss\": sae_reconstruction_loss, \"frequent_sparsity_loss\": sae_sparsity_loss, \"frequent_total_loss\": total_loss})\n",
    "            \n",
    "# wandb.finish()\n",
    "torch.save(sae.state_dict(), 'sae_large_model_weights.pth')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save the model weights (2**14 size)\n",
    "torch.save(sae.state_dict(), 'sae_14_model_weights.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
